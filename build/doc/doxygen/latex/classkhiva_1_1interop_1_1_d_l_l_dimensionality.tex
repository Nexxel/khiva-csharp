\hypertarget{classkhiva_1_1interop_1_1_d_l_l_dimensionality}{}\section{khiva.\+interop.\+D\+L\+L\+Dimensionality Class Reference}
\label{classkhiva_1_1interop_1_1_d_l_l_dimensionality}\index{khiva.\+interop.\+D\+L\+L\+Dimensionality@{khiva.\+interop.\+D\+L\+L\+Dimensionality}}


\mbox{\hyperlink{classkhiva_1_1_khiva}{Khiva}} Dimensionality class containing several dimensionality reduction methods.  


\subsection*{Static Public Member Functions}
\begin{DoxyCompactItemize}
\item 
static void \mbox{\hyperlink{classkhiva_1_1interop_1_1_d_l_l_dimensionality_a4c419ec83c5c61c775ed3b3fc2940517}{paa}} (\mbox{[}In\mbox{]} ref Int\+Ptr a, \mbox{[}In\mbox{]} ref int bins, \mbox{[}Out\mbox{]} out Int\+Ptr result)
\begin{DoxyCompactList}\small\item\em Piecewise Aggregate Approximation (P\+AA) approximates a time series $X$ of length $n$ into vector $\bar{X}=(\bar{x}_{1},…,\bar{x}_{M})$ of any arbitrary length $M \leq n$ where each of $\bar{x_{i}}$ is calculated as follows\+: \[ \bar{x}_{i} = \frac{M}{n} \sum_{j=n/M(i-1)+1}^{(n/M)i} x_{j}. \] Which simply means that in order to reduce the dimensionality from $n$ to $M$, we first divide the original time series into $M$ equally sized frames and secondly compute the mean values for each frame. The sequence assembled from the mean values is the P\+AA approximation (i.\+e., transform) of the original time series. /summary$>$ 
\begin{DoxyParams}{Parameters}
{\em a} & Set of points.\\
\hline
{\em bins} & Sets the total number of divisions.\\
\hline
{\em result} & An array of points with the reduced dimensionality.\\
\hline
\end{DoxyParams}
\end{DoxyCompactList}\item 
static void \mbox{\hyperlink{classkhiva_1_1interop_1_1_d_l_l_dimensionality_af5114c22229f13307ec0d9c9ac1a791a}{pip}} (\mbox{[}In\mbox{]} ref Int\+Ptr a, \mbox{[}In\mbox{]} ref int number\+\_\+ips, \mbox{[}Out\mbox{]} out Int\+Ptr result)
\begin{DoxyCompactList}\small\item\em Calculates the number of Perceptually Important Points (P\+IP) in the time series. \end{DoxyCompactList}\item 
static void \mbox{\hyperlink{classkhiva_1_1interop_1_1_d_l_l_dimensionality_ab5c72fe004f84626d33b2037f0edc8fc}{pla\+\_\+bottom\+\_\+up}} (\mbox{[}In\mbox{]} ref Int\+Ptr ts, \mbox{[}In\mbox{]} ref float max\+\_\+error, \mbox{[}Out\mbox{]} out Int\+Ptr result)
\begin{DoxyCompactList}\small\item\em Applies the Piecewise Linear Approximation (P\+LA Bottom\+UP) to the time series. \end{DoxyCompactList}\item 
static void \mbox{\hyperlink{classkhiva_1_1interop_1_1_d_l_l_dimensionality_a68bebe8954becb18716bc51f83bf88ba}{pla\+\_\+sliding\+\_\+window}} (\mbox{[}In\mbox{]} ref Int\+Ptr ts, \mbox{[}In\mbox{]} ref float max\+\_\+error, \mbox{[}Out\mbox{]} out Int\+Ptr result)
\begin{DoxyCompactList}\small\item\em Applies the Piecewise Linear Approximation (P\+LA Sliding Window) to the time series. \end{DoxyCompactList}\item 
static void \mbox{\hyperlink{classkhiva_1_1interop_1_1_d_l_l_dimensionality_ab2af9b3c074719d48e011dbbda082c71}{ramer\+\_\+douglas\+\_\+peucker}} (\mbox{[}In\mbox{]} ref Int\+Ptr points, \mbox{[}In\mbox{]} ref double epsilon, \mbox{[}Out\mbox{]} out Int\+Ptr res\+\_\+points)
\begin{DoxyCompactList}\small\item\em The Ramer–\+Douglas–\+Peucker algorithm (R\+DP) is an algorithm for reducing the number of points in a curve that is approximated by a series of points. It reduces a set of points depending on the perpendicular distance of the points and epsilon, the greater epsilon, more points are deleted. \end{DoxyCompactList}\item 
static void \mbox{\hyperlink{classkhiva_1_1interop_1_1_d_l_l_dimensionality_af18beafb24bed357a0860b448d42ee33}{sax}} (\mbox{[}In\mbox{]} ref Int\+Ptr a, \mbox{[}In\mbox{]} ref int alphabet\+\_\+size, \mbox{[}Out\mbox{]} out Int\+Ptr result)
\begin{DoxyCompactList}\small\item\em Symbolic Aggregate appro\+Ximation (S\+AX). It transforms a numeric time series into a time series of symbols with the same size. The algorithm was proposed by Lin et al.) and extends the P\+A\+A-\/based approach inheriting the original algorithm simplicity and low computational complexity while providing satisfactory sensitivity and selectivity in range query processing. Moreover, the use of a symbolic representation opened a door to the existing wealth of data-\/structures and string-\/manipulation algorithms in computer science such as hashing, regular expression, pattern matching, suffix trees, and grammatical inference. \end{DoxyCompactList}\item 
static void \mbox{\hyperlink{classkhiva_1_1interop_1_1_d_l_l_dimensionality_af04060492f8d33205549517696003194}{visvalingam}} (\mbox{[}In\mbox{]} ref Int\+Ptr points, \mbox{[}In\mbox{]} ref int num\+\_\+points, \mbox{[}Out\mbox{]} out Int\+Ptr res\+\_\+points)
\begin{DoxyCompactList}\small\item\em Reduces a set of points by applying the Visvalingam method (minimum triangle area) until the number of points is reduced to num\+Points. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\mbox{\hyperlink{classkhiva_1_1_khiva}{Khiva}} Dimensionality class containing several dimensionality reduction methods. 



Definition at line 19 of file D\+L\+L\+Dimensionality.\+cs.



\subsection{Member Function Documentation}
\mbox{\Hypertarget{classkhiva_1_1interop_1_1_d_l_l_dimensionality_a4c419ec83c5c61c775ed3b3fc2940517}\label{classkhiva_1_1interop_1_1_d_l_l_dimensionality_a4c419ec83c5c61c775ed3b3fc2940517}} 
\index{khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}!paa@{paa}}
\index{paa@{paa}!khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}}
\subsubsection{\texorpdfstring{paa()}{paa()}}
{\footnotesize\ttfamily static void khiva.\+interop.\+D\+L\+L\+Dimensionality.\+paa (\begin{DoxyParamCaption}\item[{\mbox{[}\+In\mbox{]} ref Int\+Ptr}]{a,  }\item[{\mbox{[}\+In\mbox{]} ref int}]{bins,  }\item[{\mbox{[}\+Out\mbox{]} out Int\+Ptr}]{result }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Piecewise Aggregate Approximation (P\+AA) approximates a time series $X$ of length $n$ into vector $\bar{X}=(\bar{x}_{1},…,\bar{x}_{M})$ of any arbitrary length $M \leq n$ where each of $\bar{x_{i}}$ is calculated as follows\+: \[ \bar{x}_{i} = \frac{M}{n} \sum_{j=n/M(i-1)+1}^{(n/M)i} x_{j}. \] Which simply means that in order to reduce the dimensionality from $n$ to $M$, we first divide the original time series into $M$ equally sized frames and secondly compute the mean values for each frame. The sequence assembled from the mean values is the P\+AA approximation (i.\+e., transform) of the original time series. /summary$>$ 
\begin{DoxyParams}{Parameters}
{\em a} & Set of points.\\
\hline
{\em bins} & Sets the total number of divisions.\\
\hline
{\em result} & An array of points with the reduced dimensionality.\\
\hline
\end{DoxyParams}


\mbox{\Hypertarget{classkhiva_1_1interop_1_1_d_l_l_dimensionality_af5114c22229f13307ec0d9c9ac1a791a}\label{classkhiva_1_1interop_1_1_d_l_l_dimensionality_af5114c22229f13307ec0d9c9ac1a791a}} 
\index{khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}!pip@{pip}}
\index{pip@{pip}!khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}}
\subsubsection{\texorpdfstring{pip()}{pip()}}
{\footnotesize\ttfamily static void khiva.\+interop.\+D\+L\+L\+Dimensionality.\+pip (\begin{DoxyParamCaption}\item[{\mbox{[}\+In\mbox{]} ref Int\+Ptr}]{a,  }\item[{\mbox{[}\+In\mbox{]} ref int}]{number\+\_\+ips,  }\item[{\mbox{[}\+Out\mbox{]} out Int\+Ptr}]{result }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Calculates the number of Perceptually Important Points (P\+IP) in the time series. 

\mbox{[}1\mbox{]} Fu TC, Chung FL, Luk R, and Ng CM. Representing financial time series based on data point importance. Engineering Applications of Artificial Intelligence, 21(2)\+:277-\/300, 2008. /summary$>$ 
\begin{DoxyParams}{Parameters}
{\em a} & Expects an input array whose dimension zero is the length of the time series.\\
\hline
{\em number\+\_\+ips} & The number of points to be returned.\\
\hline
{\em result} & Array with the most Perceptually Important number\+\_\+ips.\\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classkhiva_1_1interop_1_1_d_l_l_dimensionality_ab5c72fe004f84626d33b2037f0edc8fc}\label{classkhiva_1_1interop_1_1_d_l_l_dimensionality_ab5c72fe004f84626d33b2037f0edc8fc}} 
\index{khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}!pla\+\_\+bottom\+\_\+up@{pla\+\_\+bottom\+\_\+up}}
\index{pla\+\_\+bottom\+\_\+up@{pla\+\_\+bottom\+\_\+up}!khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}}
\subsubsection{\texorpdfstring{pla\+\_\+bottom\+\_\+up()}{pla\_bottom\_up()}}
{\footnotesize\ttfamily static void khiva.\+interop.\+D\+L\+L\+Dimensionality.\+pla\+\_\+bottom\+\_\+up (\begin{DoxyParamCaption}\item[{\mbox{[}\+In\mbox{]} ref Int\+Ptr}]{ts,  }\item[{\mbox{[}\+In\mbox{]} ref float}]{max\+\_\+error,  }\item[{\mbox{[}\+Out\mbox{]} out Int\+Ptr}]{result }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Applies the Piecewise Linear Approximation (P\+LA Bottom\+UP) to the time series. 

\mbox{[}1\mbox{]} Zhu Y, Wu D, Li Sh (2007). A Piecewise Linear Representation Method of Time Series Based on Feature Points. Knowledge-\/\+Based Intelligent Information and Engineering Systems 4693\+:1066-\/1072. /summary$>$ 
\begin{DoxyParams}{Parameters}
{\em ts} & Expects a khiva\+\_\+array containing the set of points to be reduced. The first component of the points in the first column and the second component of the points in the second column.\\
\hline
{\em max\+\_\+error} & The maximum approximation error allowed.\\
\hline
{\em result} & The reduced number of points.\\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classkhiva_1_1interop_1_1_d_l_l_dimensionality_a68bebe8954becb18716bc51f83bf88ba}\label{classkhiva_1_1interop_1_1_d_l_l_dimensionality_a68bebe8954becb18716bc51f83bf88ba}} 
\index{khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}!pla\+\_\+sliding\+\_\+window@{pla\+\_\+sliding\+\_\+window}}
\index{pla\+\_\+sliding\+\_\+window@{pla\+\_\+sliding\+\_\+window}!khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}}
\subsubsection{\texorpdfstring{pla\+\_\+sliding\+\_\+window()}{pla\_sliding\_window()}}
{\footnotesize\ttfamily static void khiva.\+interop.\+D\+L\+L\+Dimensionality.\+pla\+\_\+sliding\+\_\+window (\begin{DoxyParamCaption}\item[{\mbox{[}\+In\mbox{]} ref Int\+Ptr}]{ts,  }\item[{\mbox{[}\+In\mbox{]} ref float}]{max\+\_\+error,  }\item[{\mbox{[}\+Out\mbox{]} out Int\+Ptr}]{result }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Applies the Piecewise Linear Approximation (P\+LA Sliding Window) to the time series. 

\mbox{[}1\mbox{]} Zhu Y, Wu D, Li Sh (2007). A Piecewise Linear Representation Method of Time Series Based on Feature Points. Knowledge-\/\+Based Intelligent Information and Engineering Systems 4693\+:1066-\/1072. /summary$>$ 
\begin{DoxyParams}{Parameters}
{\em ts} & Expects a khiva\+\_\+array containing the set of points to be reduced. The first component of the points in the first column and the second component of the points in the second column.\\
\hline
{\em max\+\_\+error} & The maximum approximation error allowed.\\
\hline
{\em result} & The reduced number of points.\\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classkhiva_1_1interop_1_1_d_l_l_dimensionality_ab2af9b3c074719d48e011dbbda082c71}\label{classkhiva_1_1interop_1_1_d_l_l_dimensionality_ab2af9b3c074719d48e011dbbda082c71}} 
\index{khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}!ramer\+\_\+douglas\+\_\+peucker@{ramer\+\_\+douglas\+\_\+peucker}}
\index{ramer\+\_\+douglas\+\_\+peucker@{ramer\+\_\+douglas\+\_\+peucker}!khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}}
\subsubsection{\texorpdfstring{ramer\+\_\+douglas\+\_\+peucker()}{ramer\_douglas\_peucker()}}
{\footnotesize\ttfamily static void khiva.\+interop.\+D\+L\+L\+Dimensionality.\+ramer\+\_\+douglas\+\_\+peucker (\begin{DoxyParamCaption}\item[{\mbox{[}\+In\mbox{]} ref Int\+Ptr}]{points,  }\item[{\mbox{[}\+In\mbox{]} ref double}]{epsilon,  }\item[{\mbox{[}\+Out\mbox{]} out Int\+Ptr}]{res\+\_\+points }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



The Ramer–\+Douglas–\+Peucker algorithm (R\+DP) is an algorithm for reducing the number of points in a curve that is approximated by a series of points. It reduces a set of points depending on the perpendicular distance of the points and epsilon, the greater epsilon, more points are deleted. 

\mbox{[}1\mbox{]} Urs Ramer, \char`\"{}\+An iterative procedure for the polygonal approximation of plane curves\char`\"{}, Computer Graphics and Image Processing, 1(3), 244–256 (1972) doi\+:10.\+1016/\+S0146-\/664X(72)80017-\/0.

\mbox{[}2\mbox{]} David Douglas \& Thomas Peucker, \char`\"{}\+Algorithms for the reduction of the number of points required to represent a
digitized line or its caricature\char`\"{}, The Canadian Cartographer 10(2), 112–122 (1973) doi\+:10.\+3138/\+F\+M57-\/6770-\/\+U75\+U-\/7727 /summary$>$ 
\begin{DoxyParams}{Parameters}
{\em points} & Array with the x-\/coordinates and y-\/coordinates of the input points (x in column 0 and y in column 1).\\
\hline
{\em epsilon} & It acts as the threshold value to decide which points should be considered meaningful or not.\\
\hline
{\em res\+\_\+points} & Array with the x-\/coordinates and y-\/coordinates of the selected points (x in column 0 and y in column 1).\\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classkhiva_1_1interop_1_1_d_l_l_dimensionality_af18beafb24bed357a0860b448d42ee33}\label{classkhiva_1_1interop_1_1_d_l_l_dimensionality_af18beafb24bed357a0860b448d42ee33}} 
\index{khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}!sax@{sax}}
\index{sax@{sax}!khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}}
\subsubsection{\texorpdfstring{sax()}{sax()}}
{\footnotesize\ttfamily static void khiva.\+interop.\+D\+L\+L\+Dimensionality.\+sax (\begin{DoxyParamCaption}\item[{\mbox{[}\+In\mbox{]} ref Int\+Ptr}]{a,  }\item[{\mbox{[}\+In\mbox{]} ref int}]{alphabet\+\_\+size,  }\item[{\mbox{[}\+Out\mbox{]} out Int\+Ptr}]{result }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Symbolic Aggregate appro\+Ximation (S\+AX). It transforms a numeric time series into a time series of symbols with the same size. The algorithm was proposed by Lin et al.) and extends the P\+A\+A-\/based approach inheriting the original algorithm simplicity and low computational complexity while providing satisfactory sensitivity and selectivity in range query processing. Moreover, the use of a symbolic representation opened a door to the existing wealth of data-\/structures and string-\/manipulation algorithms in computer science such as hashing, regular expression, pattern matching, suffix trees, and grammatical inference. 

\mbox{[}1\mbox{]} Lin, J., Keogh, E., Lonardi, S. \& Chiu, B. (2003) A Symbolic Representation of Time Series, with Implications for Streaming Algorithms. In proceedings of the 8th A\+CM S\+I\+G\+M\+OD Workshop on Research Issues in Data Mining and Knowledge Discovery. San Diego, CA. June 13. /summary$>$ 
\begin{DoxyParams}{Parameters}
{\em a} & Array with the input time series.\\
\hline
{\em alphabet\+\_\+size} & Number of element within the alphabet.\\
\hline
{\em result} & An array of symbols.\\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classkhiva_1_1interop_1_1_d_l_l_dimensionality_af04060492f8d33205549517696003194}\label{classkhiva_1_1interop_1_1_d_l_l_dimensionality_af04060492f8d33205549517696003194}} 
\index{khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}!visvalingam@{visvalingam}}
\index{visvalingam@{visvalingam}!khiva\+::interop\+::\+D\+L\+L\+Dimensionality@{khiva\+::interop\+::\+D\+L\+L\+Dimensionality}}
\subsubsection{\texorpdfstring{visvalingam()}{visvalingam()}}
{\footnotesize\ttfamily static void khiva.\+interop.\+D\+L\+L\+Dimensionality.\+visvalingam (\begin{DoxyParamCaption}\item[{\mbox{[}\+In\mbox{]} ref Int\+Ptr}]{points,  }\item[{\mbox{[}\+In\mbox{]} ref int}]{num\+\_\+points,  }\item[{\mbox{[}\+Out\mbox{]} out Int\+Ptr}]{res\+\_\+points }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



Reduces a set of points by applying the Visvalingam method (minimum triangle area) until the number of points is reduced to num\+Points. 

\mbox{[}1\mbox{]} M. Visvalingam and J. D. Whyatt, Line generalisation by repeated elimination of points, The Cartographic Journal, 1993. 


\begin{DoxyParams}{Parameters}
{\em points} & Array with the x-\/coordinates and y-\/coordinates of the input points (x in column 0 and y in column 1).\\
\hline
{\em num\+\_\+points} & Sets the number of points returned after the execution of the method.\\
\hline
{\em res\+\_\+points} & Array with the x-\/coordinates and y-\/coordinates of the selected points (x in column 0 and y in column 1).\\
\hline
\end{DoxyParams}


The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{_d_l_l_dimensionality_8cs}{D\+L\+L\+Dimensionality.\+cs}}\end{DoxyCompactItemize}
